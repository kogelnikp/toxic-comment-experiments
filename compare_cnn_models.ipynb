{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/philipp/miniconda3/envs/tensorflow/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import utils\n",
    "import time\n",
    "\n",
    "from keras.models import Model, Input\n",
    "from keras.layers import Dense, Conv1D, BatchNormalization, GlobalMaxPooling1D, Dropout, \\\n",
    "    Embedding, Concatenate, SpatialDropout1D, MaxPooling1D\n",
    "\n",
    "from utils.preprocessing_utils import tokenize_sentences, convert_tokens_to_padded_sequence\n",
    "from utils.dataset_utils import load_data_from_csv\n",
    "from utils.embedding_utils import load_word2vec_embeddings, create_initial_embedding_matrix\n",
    "from utils.training_utils import train_model, train_and_evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils.keras_utils' from '/home/philipp/work/gitprojects/toxic-comment-experiments/utils/keras_utils.py'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import utils\n",
    "importlib.reload(utils.embedding_utils)\n",
    "importlib.reload(utils.dataset_utils)\n",
    "importlib.reload(utils.preprocessing_utils)\n",
    "importlib.reload(utils.training_utils)\n",
    "importlib.reload(utils.keras_utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Global parameters which hold for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_seed = 2018\n",
    "classes = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']\n",
    "features = 'comment_text'\n",
    "np.random.seed(random_seed)\n",
    "path_train_data = 'data/kaggle/train.csv'\n",
    "path_test_data = 'data/kaggle/test_complete.csv'\n",
    "path_tokenizer = 'data/models/word_tokenizer.pickle'\n",
    "\n",
    "embedding_length = 300\n",
    "path_embeddings = 'data/embeddings/GoogleNews-vectors-negative300.bin.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load train and test data and pretrained word2vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, Y_train = load_data_from_csv(path_train_data, features, classes)\n",
    "X_test, Y_test = load_data_from_csv(path_test_data, features, classes)\n",
    "\n",
    "emb_idx, emb_mean, emb_std = load_word2vec_embeddings(path_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing and tokenizatin of train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_tok = tokenize_sentences(X_train)\n",
    "del X_train\n",
    "X_test_tok = tokenize_sentences(X_test)\n",
    "del X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create initial embedding matrix for neural network and word -> idx mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens: 326175\n",
      "Number of tokens found in pretrained embeddings: 74211\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix, word_embedding_mapping = create_initial_embedding_matrix(X_train_tok, X_test_tok, emb_idx, emb_mean, emb_std, embedding_length, debug=True)\n",
    "del emb_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform comments in train and test data to padded matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_len_train = X_train_tok.apply(lambda x: len(x)).max()\n",
    "max_len_test = X_test_tok.apply(lambda x: len(x)).max()\n",
    "# limit length to 2000, otherwise we get a MemoryError\n",
    "max_comment_length = 2000\n",
    "X_train_input = convert_tokens_to_padded_sequence(X_train_tok, word_embedding_mapping, max_comment_length)\n",
    "del X_train_tok\n",
    "X_test_input = convert_tokens_to_padded_sequence(X_test_tok, word_embedding_mapping, max_comment_length)\n",
    "del X_test_tok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Singlelayer CNN with a single window size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This simple CNN consists of an embedding layer, a single convolution layer with a fixed window size and a fully connected hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m1_kernel_size = 3\n",
    "m1_hidden_dim = 100\n",
    "m1_num_filters = 150\n",
    "m1_dropout = 0.4\n",
    "m1_spatial_dropout = 0.2\n",
    "m1_batch_size = 64\n",
    "m1_epochs = 5\n",
    "\n",
    "m1_weights_path = 'data/models/cnn_simple/model{}.hdf5'\n",
    "m1_scores_path = 'data/scores/cnn_simple/scores_{}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 2000, 300)         97852800  \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 2000, 300)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 2000, 150)         135150    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               15100     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 606       \n",
      "=================================================================\n",
      "Total params: 98,003,656\n",
      "Trainable params: 98,003,656\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m1_input = Input((max_comment_length,))\n",
    "m1_word_emb = Embedding(input_dim=len(embedding_matrix), output_dim=embedding_length, input_length=max_comment_length, weights=[embedding_matrix])(m1_input)\n",
    "m1_word_emb = SpatialDropout1D(m1_spatial_dropout)(m1_word_emb)\n",
    "\n",
    "m1_conv1 = Conv1D(kernel_size=m1_kernel_size, filters=m1_num_filters, padding='same')(m1_word_emb)\n",
    "m1_conv1 = GlobalMaxPooling1D()(m1_conv1)\n",
    "\n",
    "m1_fc2 = Dense(m1_hidden_dim, activation='relu')(m1_conv1)\n",
    "m1_dropout2 = Dropout(m1_dropout)(m1_fc2)\n",
    "m1_output = Dense(len(classes), activation='sigmoid')(m1_dropout2)\n",
    "\n",
    "m1_model = Model(inputs=[m1_input], outputs=[m1_output])\n",
    "m1_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN 1/5\n",
      "Train on 159571 samples, validate on 63978 samples\n",
      "Epoch 1/5\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0621 - acc: 0.9790"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/philipp/miniconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " train: ROC-AUC - epoch: 1 - score: 0.99328\n",
      " Tox: 0.99078 - STox: 0.99115 - Obs: 0.99486 - Thr: 0.98640 - Ins: 0.99088 - IdH: 0.98296\n",
      " train: F1 Score - epoch: 1 - score: 0.78430\n",
      " Tox: 0.84888 - STox: 0.22837 - Obs: 0.84299 - Thr: 0.00000 - Ins: 0.75970 - IdH: 0.08625\n",
      "\n",
      " val: ROC-AUC - epoch: 1 - score: 0.97821\n",
      " Tox: 0.96405 - STox: 0.98478 - Obs: 0.97667 - Thr: 0.97369 - Ins: 0.97125 - IdH: 0.96928\n",
      " val: F1 Score - epoch: 1 - score: 0.64034\n",
      " Tox: 0.66049 - STox: 0.26038 - Obs: 0.68823 - Thr: 0.00000 - Ins: 0.64561 - IdH: 0.11068\n",
      "159571/159571 [==============================] - 430s 3ms/step - loss: 0.0621 - acc: 0.9790 - val_loss: 0.0760 - val_acc: 0.9695\n",
      "Epoch 2/5\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0389 - acc: 0.9846\n",
      " train: ROC-AUC - epoch: 2 - score: 0.99671\n",
      " Tox: 0.99578 - STox: 0.99362 - Obs: 0.99700 - Thr: 0.99628 - Ins: 0.99451 - IdH: 0.99456\n",
      " train: F1 Score - epoch: 2 - score: 0.80602\n",
      " Tox: 0.87107 - STox: 0.03075 - Obs: 0.85524 - Thr: 0.09109 - Ins: 0.78690 - IdH: 0.40217\n",
      "\n",
      " val: ROC-AUC - epoch: 2 - score: 0.97932\n",
      " Tox: 0.96315 - STox: 0.98674 - Obs: 0.97454 - Thr: 0.98653 - Ins: 0.97109 - IdH: 0.97744\n",
      " val: F1 Score - epoch: 2 - score: 0.64637\n",
      " Tox: 0.67887 - STox: 0.02667 - Obs: 0.67986 - Thr: 0.14346 - Ins: 0.62565 - IdH: 0.37920\n",
      "159571/159571 [==============================] - 427s 3ms/step - loss: 0.0389 - acc: 0.9845 - val_loss: 0.0668 - val_acc: 0.9729\n",
      "Epoch 3/5\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0304 - acc: 0.9875\n",
      " train: ROC-AUC - epoch: 3 - score: 0.99824\n",
      " Tox: 0.99822 - STox: 0.99507 - Obs: 0.99836 - Thr: 0.99856 - Ins: 0.99668 - IdH: 0.99789\n",
      " train: F1 Score - epoch: 3 - score: 0.88547\n",
      " Tox: 0.93675 - STox: 0.39051 - Obs: 0.91306 - Thr: 0.56842 - Ins: 0.86386 - IdH: 0.71487\n",
      "\n",
      " val: ROC-AUC - epoch: 3 - score: 0.97836\n",
      " Tox: 0.96084 - STox: 0.98728 - Obs: 0.97480 - Thr: 0.98530 - Ins: 0.97011 - IdH: 0.97787\n",
      " val: F1 Score - epoch: 3 - score: 0.61790\n",
      " Tox: 0.60192 - STox: 0.29893 - Obs: 0.67154 - Thr: 0.49600 - Ins: 0.64266 - IdH: 0.53356\n",
      "159571/159571 [==============================] - 426s 3ms/step - loss: 0.0304 - acc: 0.9875 - val_loss: 0.0793 - val_acc: 0.9651\n",
      "Epoch 4/5\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0242 - acc: 0.9902\n",
      " train: ROC-AUC - epoch: 4 - score: 0.99898\n",
      " Tox: 0.99909 - STox: 0.99719 - Obs: 0.99920 - Thr: 0.99932 - Ins: 0.99821 - IdH: 0.99868\n",
      " train: F1 Score - epoch: 4 - score: 0.91448\n",
      " Tox: 0.95212 - STox: 0.63670 - Obs: 0.93421 - Thr: 0.65645 - Ins: 0.89900 - IdH: 0.81089\n",
      "\n",
      " val: ROC-AUC - epoch: 4 - score: 0.97767\n",
      " Tox: 0.95851 - STox: 0.98470 - Obs: 0.97367 - Thr: 0.98415 - Ins: 0.96894 - IdH: 0.97412\n",
      " val: F1 Score - epoch: 4 - score: 0.61992\n",
      " Tox: 0.61626 - STox: 0.30595 - Obs: 0.65114 - Thr: 0.40731 - Ins: 0.64367 - IdH: 0.53917\n",
      "159571/159571 [==============================] - 427s 3ms/step - loss: 0.0241 - acc: 0.9902 - val_loss: 0.0861 - val_acc: 0.9646\n",
      "Epoch 5/5\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0192 - acc: 0.9923\n",
      " train: ROC-AUC - epoch: 5 - score: 0.99946\n",
      " Tox: 0.99959 - STox: 0.99797 - Obs: 0.99954 - Thr: 0.99923 - Ins: 0.99910 - IdH: 0.99907\n",
      " train: F1 Score - epoch: 5 - score: 0.94011\n",
      " Tox: 0.97220 - STox: 0.76360 - Obs: 0.95078 - Thr: 0.60976 - Ins: 0.93389 - IdH: 0.85606\n",
      "\n",
      " val: ROC-AUC - epoch: 5 - score: 0.97570\n",
      " Tox: 0.95533 - STox: 0.98353 - Obs: 0.97265 - Thr: 0.97914 - Ins: 0.96691 - IdH: 0.97186\n",
      " val: F1 Score - epoch: 5 - score: 0.59931\n",
      " Tox: 0.58264 - STox: 0.34113 - Obs: 0.64999 - Thr: 0.33994 - Ins: 0.63996 - IdH: 0.53254\n",
      "159571/159571 [==============================] - 426s 3ms/step - loss: 0.0192 - acc: 0.9923 - val_loss: 0.1077 - val_acc: 0.9603\n",
      "RUN 2/5\n",
      "Train on 159571 samples, validate on 63978 samples\n",
      "Epoch 1/5\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0618 - acc: 0.9793\n",
      " train: ROC-AUC - epoch: 1 - score: 0.99308\n",
      " Tox: 0.99022 - STox: 0.99091 - Obs: 0.99476 - Thr: 0.98539 - Ins: 0.99084 - IdH: 0.98128\n",
      " train: F1 Score - epoch: 1 - score: 0.78453\n",
      " Tox: 0.84364 - STox: 0.25867 - Obs: 0.84386 - Thr: 0.00000 - Ins: 0.77007 - IdH: 0.01132\n",
      "\n",
      " val: ROC-AUC - epoch: 1 - score: 0.97808\n",
      " Tox: 0.96287 - STox: 0.98352 - Obs: 0.97523 - Thr: 0.97485 - Ins: 0.97097 - IdH: 0.96636\n",
      " val: F1 Score - epoch: 1 - score: 0.63292\n",
      " Tox: 0.66484 - STox: 0.27203 - Obs: 0.65380 - Thr: 0.00000 - Ins: 0.64494 - IdH: 0.00839\n",
      "159571/159571 [==============================] - 428s 3ms/step - loss: 0.0618 - acc: 0.9793 - val_loss: 0.0763 - val_acc: 0.9682\n",
      "Epoch 2/5\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0392 - acc: 0.9845\n",
      " train: ROC-AUC - epoch: 2 - score: 0.99686\n",
      " Tox: 0.99643 - STox: 0.99362 - Obs: 0.99727 - Thr: 0.99612 - Ins: 0.99463 - IdH: 0.99428\n",
      " train: F1 Score - epoch: 2 - score: 0.84455\n",
      " Tox: 0.90601 - STox: 0.31335 - Obs: 0.88239 - Thr: 0.43114 - Ins: 0.82527 - IdH: 0.41012\n",
      "\n",
      " val: ROC-AUC - epoch: 2 - score: 0.97859\n",
      " Tox: 0.96005 - STox: 0.98545 - Obs: 0.97500 - Thr: 0.98187 - Ins: 0.97088 - IdH: 0.97544\n",
      " val: F1 Score - epoch: 2 - score: 0.62932\n",
      " Tox: 0.62167 - STox: 0.23909 - Obs: 0.67841 - Thr: 0.35556 - Ins: 0.65725 - IdH: 0.45464\n",
      "159571/159571 [==============================] - 428s 3ms/step - loss: 0.0392 - acc: 0.9845 - val_loss: 0.0769 - val_acc: 0.9670\n",
      "Epoch 3/5\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0303 - acc: 0.9876\n",
      " train: ROC-AUC - epoch: 3 - score: 0.99817\n",
      " Tox: 0.99817 - STox: 0.99563 - Obs: 0.99852 - Thr: 0.99820 - Ins: 0.99668 - IdH: 0.99741\n",
      " train: F1 Score - epoch: 3 - score: 0.88463\n",
      " Tox: 0.93654 - STox: 0.38899 - Obs: 0.91172 - Thr: 0.43505 - Ins: 0.86932 - IdH: 0.64836\n",
      "\n",
      " val: ROC-AUC - epoch: 3 - score: 0.97762\n",
      " Tox: 0.96051 - STox: 0.98577 - Obs: 0.97486 - Thr: 0.98038 - Ins: 0.97050 - IdH: 0.97575\n",
      " val: F1 Score - epoch: 3 - score: 0.60106\n",
      " Tox: 0.57769 - STox: 0.25899 - Obs: 0.65245 - Thr: 0.26316 - Ins: 0.65033 - IdH: 0.52860\n",
      "159571/159571 [==============================] - 428s 3ms/step - loss: 0.0303 - acc: 0.9876 - val_loss: 0.0982 - val_acc: 0.9604\n",
      "Epoch 4/5\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0238 - acc: 0.9903\n",
      " train: ROC-AUC - epoch: 4 - score: 0.99882\n",
      " Tox: 0.99935 - STox: 0.99691 - Obs: 0.99931 - Thr: 0.99896 - Ins: 0.99810 - IdH: 0.99850\n",
      " train: F1 Score - epoch: 4 - score: 0.90663\n",
      " Tox: 0.94533 - STox: 0.54911 - Obs: 0.94266 - Thr: 0.61330 - Ins: 0.89803 - IdH: 0.61423\n",
      "\n",
      " val: ROC-AUC - epoch: 4 - score: 0.97517\n",
      " Tox: 0.95640 - STox: 0.98144 - Obs: 0.97270 - Thr: 0.97645 - Ins: 0.97022 - IdH: 0.97087\n",
      " val: F1 Score - epoch: 4 - score: 0.58384\n",
      " Tox: 0.54971 - STox: 0.27179 - Obs: 0.65404 - Thr: 0.34286 - Ins: 0.65169 - IdH: 0.48609\n",
      "159571/159571 [==============================] - 427s 3ms/step - loss: 0.0238 - acc: 0.9903 - val_loss: 0.1048 - val_acc: 0.9579\n",
      "Epoch 5/5\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0187 - acc: 0.9925\n",
      " train: ROC-AUC - epoch: 5 - score: 0.99951\n",
      " Tox: 0.99972 - STox: 0.99784 - Obs: 0.99960 - Thr: 0.99924 - Ins: 0.99901 - IdH: 0.99913\n",
      " train: F1 Score - epoch: 5 - score: 0.94107\n",
      " Tox: 0.97695 - STox: 0.71567 - Obs: 0.95576 - Thr: 0.70886 - Ins: 0.92590 - IdH: 0.83593\n",
      "\n",
      " val: ROC-AUC - epoch: 5 - score: 0.97580\n",
      " Tox: 0.95526 - STox: 0.98369 - Obs: 0.97276 - Thr: 0.97916 - Ins: 0.96678 - IdH: 0.97192\n",
      " val: F1 Score - epoch: 5 - score: 0.61113\n",
      " Tox: 0.59968 - STox: 0.32298 - Obs: 0.66437 - Thr: 0.45810 - Ins: 0.63117 - IdH: 0.54401\n",
      "159571/159571 [==============================] - 427s 3ms/step - loss: 0.0187 - acc: 0.9925 - val_loss: 0.1029 - val_acc: 0.9646\n",
      "RUN 3/5\n",
      "Train on 159571 samples, validate on 63978 samples\n",
      "Epoch 1/5\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9787\n",
      " train: ROC-AUC - epoch: 1 - score: 0.99292\n",
      " Tox: 0.99040 - STox: 0.99127 - Obs: 0.99451 - Thr: 0.98267 - Ins: 0.99012 - IdH: 0.97943\n",
      " train: F1 Score - epoch: 1 - score: 0.77160\n",
      " Tox: 0.83159 - STox: 0.20639 - Obs: 0.84057 - Thr: 0.00000 - Ins: 0.74759 - IdH: 0.00850\n",
      "\n",
      " val: ROC-AUC - epoch: 1 - score: 0.97803\n",
      " Tox: 0.96369 - STox: 0.98342 - Obs: 0.97694 - Thr: 0.96780 - Ins: 0.96956 - IdH: 0.96453\n",
      " val: F1 Score - epoch: 1 - score: 0.63882\n",
      " Tox: 0.67452 - STox: 0.22904 - Obs: 0.67401 - Thr: 0.00000 - Ins: 0.63043 - IdH: 0.00839\n",
      "159571/159571 [==============================] - 427s 3ms/step - loss: 0.0628 - acc: 0.9787 - val_loss: 0.0755 - val_acc: 0.9699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0398 - acc: 0.9844\n",
      " train: ROC-AUC - epoch: 2 - score: 0.99651\n",
      " Tox: 0.99586 - STox: 0.99360 - Obs: 0.99710 - Thr: 0.99400 - Ins: 0.99402 - IdH: 0.99304\n",
      " train: F1 Score - epoch: 2 - score: 0.82295\n",
      " Tox: 0.87953 - STox: 0.26795 - Obs: 0.88185 - Thr: 0.00000 - Ins: 0.80129 - IdH: 0.41236\n",
      "\n",
      " val: ROC-AUC - epoch: 2 - score: 0.97878\n",
      " Tox: 0.96097 - STox: 0.98564 - Obs: 0.97598 - Thr: 0.98296 - Ins: 0.96953 - IdH: 0.97527\n",
      " val: F1 Score - epoch: 2 - score: 0.63269\n",
      " Tox: 0.64135 - STox: 0.15656 - Obs: 0.68198 - Thr: 0.00000 - Ins: 0.64233 - IdH: 0.41020\n",
      "159571/159571 [==============================] - 427s 3ms/step - loss: 0.0398 - acc: 0.9844 - val_loss: 0.0723 - val_acc: 0.9695\n",
      "Epoch 3/5\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0311 - acc: 0.9874\n",
      " train: ROC-AUC - epoch: 3 - score: 0.99812\n",
      " Tox: 0.99801 - STox: 0.99593 - Obs: 0.99840 - Thr: 0.99717 - Ins: 0.99664 - IdH: 0.99741\n",
      " train: F1 Score - epoch: 3 - score: 0.88145\n",
      " Tox: 0.93316 - STox: 0.60984 - Obs: 0.90794 - Thr: 0.42643 - Ins: 0.86412 - IdH: 0.54081\n",
      "\n",
      " val: ROC-AUC - epoch: 3 - score: 0.97815\n",
      " Tox: 0.95803 - STox: 0.98562 - Obs: 0.97481 - Thr: 0.98490 - Ins: 0.97088 - IdH: 0.97388\n",
      " val: F1 Score - epoch: 3 - score: 0.61095\n",
      " Tox: 0.59783 - STox: 0.33684 - Obs: 0.65905 - Thr: 0.29442 - Ins: 0.65181 - IdH: 0.46583\n",
      "159571/159571 [==============================] - 427s 3ms/step - loss: 0.0311 - acc: 0.9874 - val_loss: 0.0836 - val_acc: 0.9630\n",
      "Epoch 4/5\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0244 - acc: 0.9901\n",
      " train: ROC-AUC - epoch: 4 - score: 0.99897\n",
      " Tox: 0.99916 - STox: 0.99721 - Obs: 0.99902 - Thr: 0.99868 - Ins: 0.99805 - IdH: 0.99816\n",
      " train: F1 Score - epoch: 4 - score: 0.90951\n",
      " Tox: 0.95169 - STox: 0.70813 - Obs: 0.92647 - Thr: 0.46296 - Ins: 0.89591 - IdH: 0.72556\n",
      "\n",
      " val: ROC-AUC - epoch: 4 - score: 0.97679\n",
      " Tox: 0.95532 - STox: 0.98387 - Obs: 0.97344 - Thr: 0.98444 - Ins: 0.96750 - IdH: 0.97284\n",
      " val: F1 Score - epoch: 4 - score: 0.61405\n",
      " Tox: 0.60585 - STox: 0.34247 - Obs: 0.66771 - Thr: 0.29032 - Ins: 0.63518 - IdH: 0.51699\n",
      "159571/159571 [==============================] - 426s 3ms/step - loss: 0.0244 - acc: 0.9901 - val_loss: 0.0859 - val_acc: 0.9660\n",
      "Epoch 5/5\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0194 - acc: 0.9922\n",
      " train: ROC-AUC - epoch: 5 - score: 0.99943\n",
      " Tox: 0.99965 - STox: 0.99809 - Obs: 0.99948 - Thr: 0.99897 - Ins: 0.99897 - IdH: 0.99894\n",
      " train: F1 Score - epoch: 5 - score: 0.93718\n",
      " Tox: 0.97043 - STox: 0.76570 - Obs: 0.94762 - Thr: 0.73391 - Ins: 0.92732 - IdH: 0.83327\n",
      "\n",
      " val: ROC-AUC - epoch: 5 - score: 0.97568\n",
      " Tox: 0.95407 - STox: 0.98403 - Obs: 0.97229 - Thr: 0.98611 - Ins: 0.96595 - IdH: 0.97374\n",
      " val: F1 Score - epoch: 5 - score: 0.61038\n",
      " Tox: 0.60146 - STox: 0.34905 - Obs: 0.66279 - Thr: 0.38061 - Ins: 0.63257 - IdH: 0.56383\n",
      "159571/159571 [==============================] - 427s 3ms/step - loss: 0.0194 - acc: 0.9922 - val_loss: 0.0944 - val_acc: 0.9642\n",
      "RUN 4/5\n",
      "Train on 159571 samples, validate on 63978 samples\n",
      "Epoch 1/5\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0633 - acc: 0.9787\n",
      " train: ROC-AUC - epoch: 1 - score: 0.99288\n",
      " Tox: 0.99041 - STox: 0.99105 - Obs: 0.99447 - Thr: 0.97861 - Ins: 0.98995 - IdH: 0.98168\n",
      " train: F1 Score - epoch: 1 - score: 0.75180\n",
      " Tox: 0.80887 - STox: 0.11711 - Obs: 0.82887 - Thr: 0.00000 - Ins: 0.73381 - IdH: 0.00000\n",
      "\n",
      " val: ROC-AUC - epoch: 1 - score: 0.97774\n",
      " Tox: 0.96195 - STox: 0.98520 - Obs: 0.97528 - Thr: 0.96815 - Ins: 0.96834 - IdH: 0.96958\n",
      " val: F1 Score - epoch: 1 - score: 0.63919\n",
      " Tox: 0.67752 - STox: 0.14554 - Obs: 0.68594 - Thr: 0.00000 - Ins: 0.62557 - IdH: 0.00000\n",
      "159571/159571 [==============================] - 424s 3ms/step - loss: 0.0633 - acc: 0.9787 - val_loss: 0.0690 - val_acc: 0.9726\n",
      "Epoch 2/5\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0397 - acc: 0.9842\n",
      " train: ROC-AUC - epoch: 2 - score: 0.99656\n",
      " Tox: 0.99574 - STox: 0.99376 - Obs: 0.99718 - Thr: 0.99217 - Ins: 0.99451 - IdH: 0.99392\n",
      " train: F1 Score - epoch: 2 - score: 0.82575\n",
      " Tox: 0.88152 - STox: 0.05889 - Obs: 0.88368 - Thr: 0.00000 - Ins: 0.82693 - IdH: 0.23450\n",
      "\n",
      " val: ROC-AUC - epoch: 2 - score: 0.97929\n",
      " Tox: 0.96166 - STox: 0.98722 - Obs: 0.97621 - Thr: 0.97710 - Ins: 0.97192 - IdH: 0.97822\n",
      " val: F1 Score - epoch: 2 - score: 0.64233\n",
      " Tox: 0.65201 - STox: 0.07634 - Obs: 0.68727 - Thr: 0.00000 - Ins: 0.66462 - IdH: 0.28018\n",
      "159571/159571 [==============================] - 424s 3ms/step - loss: 0.0397 - acc: 0.9842 - val_loss: 0.0737 - val_acc: 0.9698\n",
      "Epoch 3/5\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0309 - acc: 0.9874\n",
      " train: ROC-AUC - epoch: 3 - score: 0.99805\n",
      " Tox: 0.99779 - STox: 0.99587 - Obs: 0.99854 - Thr: 0.99782 - Ins: 0.99653 - IdH: 0.99701\n",
      " train: F1 Score - epoch: 3 - score: 0.87274\n",
      " Tox: 0.92810 - STox: 0.41060 - Obs: 0.90190 - Thr: 0.27305 - Ins: 0.84899 - IdH: 0.65612\n",
      "\n",
      " val: ROC-AUC - epoch: 3 - score: 0.97786\n",
      " Tox: 0.96055 - STox: 0.98561 - Obs: 0.97488 - Thr: 0.98170 - Ins: 0.97053 - IdH: 0.97936\n",
      " val: F1 Score - epoch: 3 - score: 0.60872\n",
      " Tox: 0.58803 - STox: 0.21771 - Obs: 0.68836 - Thr: 0.15385 - Ins: 0.63697 - IdH: 0.56306\n",
      "159571/159571 [==============================] - 423s 3ms/step - loss: 0.0309 - acc: 0.9874 - val_loss: 0.0768 - val_acc: 0.9648\n",
      "Epoch 4/5\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0246 - acc: 0.9900\n",
      " train: ROC-AUC - epoch: 4 - score: 0.99893\n",
      " Tox: 0.99895 - STox: 0.99719 - Obs: 0.99909 - Thr: 0.99861 - Ins: 0.99786 - IdH: 0.99843\n",
      " train: F1 Score - epoch: 4 - score: 0.90279\n",
      " Tox: 0.94746 - STox: 0.67033 - Obs: 0.92795 - Thr: 0.56942 - Ins: 0.88141 - IdH: 0.65578\n",
      "\n",
      " val: ROC-AUC - epoch: 4 - score: 0.97684\n",
      " Tox: 0.95692 - STox: 0.98578 - Obs: 0.97328 - Thr: 0.98055 - Ins: 0.96871 - IdH: 0.97697\n",
      " val: F1 Score - epoch: 4 - score: 0.61675\n",
      " Tox: 0.61201 - STox: 0.33420 - Obs: 0.67680 - Thr: 0.37363 - Ins: 0.63011 - IdH: 0.46847\n",
      "159571/159571 [==============================] - 423s 3ms/step - loss: 0.0246 - acc: 0.9900 - val_loss: 0.0842 - val_acc: 0.9669\n",
      "Epoch 5/5\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0197 - acc: 0.9920\n",
      " train: ROC-AUC - epoch: 5 - score: 0.99946\n",
      " Tox: 0.99966 - STox: 0.99803 - Obs: 0.99956 - Thr: 0.99933 - Ins: 0.99904 - IdH: 0.99921\n",
      " train: F1 Score - epoch: 5 - score: 0.93736\n",
      " Tox: 0.96961 - STox: 0.70833 - Obs: 0.95488 - Thr: 0.72748 - Ins: 0.92963 - IdH: 0.80048\n",
      "\n",
      " val: ROC-AUC - epoch: 5 - score: 0.97427\n",
      " Tox: 0.95245 - STox: 0.98223 - Obs: 0.97005 - Thr: 0.97774 - Ins: 0.96520 - IdH: 0.97476\n",
      " val: F1 Score - epoch: 5 - score: 0.58730\n",
      " Tox: 0.56004 - STox: 0.30026 - Obs: 0.65721 - Thr: 0.39526 - Ins: 0.63568 - IdH: 0.51687\n",
      "159571/159571 [==============================] - 424s 3ms/step - loss: 0.0197 - acc: 0.9920 - val_loss: 0.0984 - val_acc: 0.9596\n",
      "RUN 5/5\n",
      "Train on 159571 samples, validate on 63978 samples\n",
      "Epoch 1/5\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0621 - acc: 0.9793\n",
      " train: ROC-AUC - epoch: 1 - score: 0.99281\n",
      " Tox: 0.99074 - STox: 0.99097 - Obs: 0.99449 - Thr: 0.98081 - Ins: 0.99018 - IdH: 0.97849\n",
      " train: F1 Score - epoch: 1 - score: 0.77105\n",
      " Tox: 0.84258 - STox: 0.17555 - Obs: 0.81980 - Thr: 0.00000 - Ins: 0.75351 - IdH: 0.00000\n",
      "\n",
      " val: ROC-AUC - epoch: 1 - score: 0.97717\n",
      " Tox: 0.96283 - STox: 0.98379 - Obs: 0.97673 - Thr: 0.97076 - Ins: 0.97021 - IdH: 0.96090\n",
      " val: F1 Score - epoch: 1 - score: 0.63861\n",
      " Tox: 0.66825 - STox: 0.18105 - Obs: 0.69030 - Thr: 0.00000 - Ins: 0.63551 - IdH: 0.00000\n",
      "159571/159571 [==============================] - 428s 3ms/step - loss: 0.0621 - acc: 0.9793 - val_loss: 0.0729 - val_acc: 0.9712\n",
      "Epoch 2/5\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0397 - acc: 0.9843\n",
      " train: ROC-AUC - epoch: 2 - score: 0.99652\n",
      " Tox: 0.99582 - STox: 0.99371 - Obs: 0.99714 - Thr: 0.99552 - Ins: 0.99431 - IdH: 0.99375\n",
      " train: F1 Score - epoch: 2 - score: 0.83365\n",
      " Tox: 0.90214 - STox: 0.00000 - Obs: 0.87946 - Thr: 0.15909 - Ins: 0.82078 - IdH: 0.20474\n",
      "\n",
      " val: ROC-AUC - epoch: 2 - score: 0.97879\n",
      " Tox: 0.96293 - STox: 0.98570 - Obs: 0.97618 - Thr: 0.98199 - Ins: 0.97240 - IdH: 0.97566\n",
      " val: F1 Score - epoch: 2 - score: 0.62231\n",
      " Tox: 0.61729 - STox: 0.00000 - Obs: 0.67633 - Thr: 0.18039 - Ins: 0.66265 - IdH: 0.25956\n",
      "159571/159571 [==============================] - 427s 3ms/step - loss: 0.0397 - acc: 0.9843 - val_loss: 0.0792 - val_acc: 0.9659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0305 - acc: 0.9875\n",
      " train: ROC-AUC - epoch: 3 - score: 0.99817\n",
      " Tox: 0.99813 - STox: 0.99575 - Obs: 0.99825 - Thr: 0.99831 - Ins: 0.99644 - IdH: 0.99763\n",
      " train: F1 Score - epoch: 3 - score: 0.87156\n",
      " Tox: 0.93459 - STox: 0.42344 - Obs: 0.90537 - Thr: 0.52705 - Ins: 0.84549 - IdH: 0.39220\n",
      "\n",
      " val: ROC-AUC - epoch: 3 - score: 0.97795\n",
      " Tox: 0.96117 - STox: 0.98534 - Obs: 0.97475 - Thr: 0.98850 - Ins: 0.97026 - IdH: 0.97484\n",
      " val: F1 Score - epoch: 3 - score: 0.61327\n",
      " Tox: 0.60004 - STox: 0.26230 - Obs: 0.67140 - Thr: 0.44444 - Ins: 0.65475 - IdH: 0.36522\n",
      "159571/159571 [==============================] - 427s 3ms/step - loss: 0.0305 - acc: 0.9875 - val_loss: 0.0798 - val_acc: 0.9650\n",
      "Epoch 4/5\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0242 - acc: 0.9901\n",
      " train: ROC-AUC - epoch: 4 - score: 0.99884\n",
      " Tox: 0.99918 - STox: 0.99617 - Obs: 0.99905 - Thr: 0.99872 - Ins: 0.99791 - IdH: 0.99824\n",
      " train: F1 Score - epoch: 4 - score: 0.90354\n",
      " Tox: 0.95317 - STox: 0.02225 - Obs: 0.93319 - Thr: 0.68293 - Ins: 0.89171 - IdH: 0.79609\n",
      "\n",
      " val: ROC-AUC - epoch: 4 - score: 0.97594\n",
      " Tox: 0.95678 - STox: 0.98007 - Obs: 0.97278 - Thr: 0.98190 - Ins: 0.96794 - IdH: 0.97398\n",
      " val: F1 Score - epoch: 4 - score: 0.59196\n",
      " Tox: 0.56126 - STox: 0.00000 - Obs: 0.65873 - Thr: 0.36820 - Ins: 0.65050 - IdH: 0.55818\n",
      "159571/159571 [==============================] - 426s 3ms/step - loss: 0.0242 - acc: 0.9901 - val_loss: 0.0957 - val_acc: 0.9602\n",
      "Epoch 5/5\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0195 - acc: 0.9921\n",
      " train: ROC-AUC - epoch: 5 - score: 0.99941\n",
      " Tox: 0.99956 - STox: 0.99805 - Obs: 0.99948 - Thr: 0.99921 - Ins: 0.99883 - IdH: 0.99921\n",
      " train: F1 Score - epoch: 5 - score: 0.93659\n",
      " Tox: 0.97043 - STox: 0.74897 - Obs: 0.95013 - Thr: 0.68387 - Ins: 0.92123 - IdH: 0.84428\n",
      "\n",
      " val: ROC-AUC - epoch: 5 - score: 0.97609\n",
      " Tox: 0.95592 - STox: 0.98102 - Obs: 0.97245 - Thr: 0.97984 - Ins: 0.96645 - IdH: 0.97488\n",
      " val: F1 Score - epoch: 5 - score: 0.59996\n",
      " Tox: 0.58218 - STox: 0.33698 - Obs: 0.64539 - Thr: 0.36937 - Ins: 0.64591 - IdH: 0.53945\n",
      "159571/159571 [==============================] - 426s 3ms/step - loss: 0.0195 - acc: 0.9921 - val_loss: 0.1059 - val_acc: 0.9611\n"
     ]
    }
   ],
   "source": [
    "m1_scores = train_and_evaluate_model(m1_model, X_train_input, Y_train, (X_test_input, Y_test), \\\n",
    "                                    m1_epochs, m1_batch_size, 'adam', 'binary_crossentropy', ['accuracy'], \\\n",
    "                                    random_seed, runs=5)\n",
    "np.save(m1_scores_path.format(time.time()), m1_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Singlelayer CNN with multiple window sizes\n",
    "This CNN consists of an embedding layer, a convolution layer with multiple window sizes which get concatenated afterwards. On top of that there is a fully connected hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m2_kernel_sizes = [3, 4, 5]\n",
    "m2_hidden_dim = 100\n",
    "m2_num_filters = [100, 100, 100]\n",
    "m2_dropout = 0.4\n",
    "m2_spatial_dropout = 0.2\n",
    "m2_batch_size = 64\n",
    "m2_epochs = 5\n",
    "\n",
    "m2_weights_path = 'data/models/cnn_multiwindowsizes/model{}.hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 2000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 2000, 300)    97852800    input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_3 (SpatialDro (None, 2000, 300)    0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 2000, 100)    90100       spatial_dropout1d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 2000, 100)    120100      spatial_dropout1d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 2000, 100)    150100      spatial_dropout1d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_7 (GlobalM (None, 100)          0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_8 (GlobalM (None, 100)          0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_9 (GlobalM (None, 100)          0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 300)          0           global_max_pooling1d_7[0][0]     \n",
      "                                                                 global_max_pooling1d_8[0][0]     \n",
      "                                                                 global_max_pooling1d_9[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 100)          30100       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 100)          0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 6)            606         dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 98,243,806\n",
      "Trainable params: 98,243,806\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m2_input = Input((max_comment_length,))\n",
    "m2_word_emb = Embedding(input_dim=len(embedding_matrix), output_dim=embedding_length, input_length=max_comment_length, weights=[embedding_matrix])(m2_input)\n",
    "m2_word_emb = SpatialDropout1D(m2_spatial_dropout)(m2_word_emb)\n",
    "\n",
    "m2_conv1 = Conv1D(kernel_size=m2_kernel_sizes[0], filters=m2_num_filters[0], padding='same')(m2_word_emb)\n",
    "m2_conv1 = GlobalMaxPooling1D()(m2_conv1)\n",
    "\n",
    "m2_conv2 = Conv1D(kernel_size=m2_kernel_sizes[1], filters=m2_num_filters[1], padding='same')(m2_word_emb)\n",
    "m2_conv2 = GlobalMaxPooling1D()(m2_conv2)\n",
    "\n",
    "m2_conv3 = Conv1D(kernel_size=m2_kernel_sizes[2], filters=m2_num_filters[2], padding='same')(m2_word_emb)\n",
    "m2_conv3 = GlobalMaxPooling1D()(m2_conv3)\n",
    "\n",
    "m2_concat4 = Concatenate()([m2_conv1, m2_conv2, m2_conv3])\n",
    "\n",
    "m2_fc5 = Dense(m2_hidden_dim, activation='relu')(m2_concat4)\n",
    "m2_fc5 = Dropout(m2_dropout)(m2_fc5)\n",
    "m2_output = Dense(len(classes), activation='sigmoid')(m2_fc5)\n",
    "\n",
    "m2_model = Model(inputs=[m2_input], outputs=[m2_output])\n",
    "m2_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 159571 samples, validate on 63978 samples\n",
      "Epoch 1/5\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0551 - acc: 0.9801\n",
      "Epoch 00001: val_loss improved from inf to 0.08369, saving model to data/models/cnn_multiwindowsizes/model1541932408.2893183\n",
      "\n",
      " train: ROC-AUC - epoch: 0 - score: 0.992644\n",
      " Tox: 0.9916101666633795 - STox: 0.9920910052921812 - Obs: 0.995355572761399 - Thr: 0.9926842150983135 - Ins: 0.9914407411046907 - IdH: 0.9926831569318832\n",
      "\n",
      " val: ROC-AUC - epoch: 0 - score: 0.978808\n",
      " Tox: 0.9668416790454769 - STox: 0.9884707745738456 - Obs: 0.9747124942865073 - Thr: 0.9866755725097227 - Ins: 0.9731549503444628 - IdH: 0.9829946756818101\n",
      "159571/159571 [==============================] - 693s 4ms/step - loss: 0.0551 - acc: 0.9801 - val_loss: 0.0837 - val_acc: 0.9651\n",
      "Epoch 2/5\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0382 - acc: 0.9846\n",
      "Epoch 00002: val_loss improved from 0.08369 to 0.08026, saving model to data/models/cnn_multiwindowsizes/model1541932408.2893183\n",
      "\n",
      " train: ROC-AUC - epoch: 1 - score: 0.995974\n",
      " Tox: 0.9964034740653277 - STox: 0.9938659862305181 - Obs: 0.9973711965699472 - Thr: 0.9971531019710662 - Ins: 0.9944256670316292 - IdH: 0.9966244235582392\n",
      "\n",
      " val: ROC-AUC - epoch: 1 - score: 0.979081\n",
      " Tox: 0.9654433854945306 - STox: 0.9882466175006063 - Obs: 0.9754851485545409 - Thr: 0.9897576611295997 - Ins: 0.9726762128143929 - IdH: 0.9828766169911453\n",
      "159571/159571 [==============================] - 691s 4ms/step - loss: 0.0382 - acc: 0.9846 - val_loss: 0.0803 - val_acc: 0.9662\n",
      "Epoch 3/5\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0301 - acc: 0.9875\n",
      "Epoch 00003: val_loss improved from 0.08026 to 0.07269, saving model to data/models/cnn_multiwindowsizes/model1541932408.2893183\n",
      "\n",
      " train: ROC-AUC - epoch: 2 - score: 0.997532\n",
      " Tox: 0.9980506431939761 - STox: 0.9949767279439137 - Obs: 0.9984261543436528 - Thr: 0.9987082566663792 - Ins: 0.9968820530283885 - IdH: 0.9981477026501685\n",
      "\n",
      " val: ROC-AUC - epoch: 2 - score: 0.979174\n",
      " Tox: 0.9640717968722344 - STox: 0.988312883694434 - Obs: 0.9760444550528617 - Thr: 0.9903432497918778 - Ins: 0.9733448897558915 - IdH: 0.9829255232144499\n",
      "159571/159571 [==============================] - 694s 4ms/step - loss: 0.0301 - acc: 0.9875 - val_loss: 0.0727 - val_acc: 0.9697\n",
      "Epoch 4/5\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0240 - acc: 0.9900\n",
      "Epoch 00004: val_loss did not improve\n",
      "\n",
      " train: ROC-AUC - epoch: 3 - score: 0.998578\n",
      " Tox: 0.9991663169681991 - STox: 0.9969683601794678 - Obs: 0.9991316708623943 - Thr: 0.9991718417271632 - Ins: 0.9980022866269541 - IdH: 0.9990299011493983\n",
      "\n",
      " val: ROC-AUC - epoch: 3 - score: 0.977178\n",
      " Tox: 0.9611809730992911 - STox: 0.9856088631698192 - Obs: 0.9747886112736901 - Thr: 0.9897340265066012 - Ins: 0.9715066811527716 - IdH: 0.9802470694449724\n",
      "159571/159571 [==============================] - 693s 4ms/step - loss: 0.0240 - acc: 0.9900 - val_loss: 0.0953 - val_acc: 0.9604\n",
      "Epoch 5/5\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0194 - acc: 0.9920\n",
      "Epoch 00005: val_loss did not improve\n",
      "\n",
      " train: ROC-AUC - epoch: 4 - score: 0.999146\n",
      " Tox: 0.9996614606948154 - STox: 0.9978092085095899 - Obs: 0.9996097866696214 - Thr: 0.9993552296337184 - Ins: 0.998972330288698 - IdH: 0.9994658096725532\n",
      "\n",
      " val: ROC-AUC - epoch: 4 - score: 0.975623\n",
      " Tox: 0.9601495677401172 - STox: 0.9843677106383627 - Obs: 0.9717775985264238 - Thr: 0.9874909670031677 - Ins: 0.9697934603350785 - IdH: 0.9801557837480913\n",
      "159571/159571 [==============================] - 691s 4ms/step - loss: 0.0194 - acc: 0.9920 - val_loss: 0.0939 - val_acc: 0.9630\n"
     ]
    }
   ],
   "source": [
    "m2_model, predictions = train_model(m2_model, X_train_input, Y_train, (X_test_input, Y_test), \\\n",
    "                                    m2_epochs, m2_batch_size, 'adam', 'binary_crossentropy', ['accuracy'], \\\n",
    "                                    m2_weights_path.format(time.time()), random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Multilayer CNN\n",
    "This architecture consists of multiple convolutional layers with a fully connected hidden layer on top of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m3_kernel_sizes = [3, 5]\n",
    "m3_hidden_dim = 100\n",
    "m3_num_filters = [150, 150]\n",
    "m3_dropout = 0.4\n",
    "m3_spatial_dropout = 0.2\n",
    "m3_batch_size = 64\n",
    "m3_epochs = 5\n",
    "\n",
    "m3_weights_path = 'data/models/cnn_multilayer/model{}.hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 2000, 300)         97852800  \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_2 (Spatial (None, 2000, 300)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 2000, 150)         135150    \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 2000, 150)         67650     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               15100     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 606       \n",
      "=================================================================\n",
      "Total params: 98,071,306\n",
      "Trainable params: 98,071,306\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m3_input = Input((max_comment_length,))\n",
    "m3_word_emb = Embedding(input_dim=len(embedding_matrix), output_dim=embedding_length, input_length=max_comment_length, weights=[embedding_matrix])(m3_input)\n",
    "m3_word_emb = SpatialDropout1D(m3_spatial_dropout)(m3_word_emb)\n",
    "\n",
    "m3_conv1 = Conv1D(kernel_size=m3_kernel_sizes[0], filters=m3_num_filters[0], padding='same')(m3_word_emb)\n",
    "#m3_conv1 = MaxPooling1D(2, strides=2)(m3_conv1)\n",
    "\n",
    "m3_conv2 = Conv1D(kernel_size=m3_kernel_sizes[1], filters=m3_num_filters[1], padding='same')(m3_conv1)\n",
    "m3_conv2 = GlobalMaxPooling1D()(m3_conv2)\n",
    "\n",
    "m3_fc3 = Dense(m3_hidden_dim, activation='relu')(m3_conv2)\n",
    "m3_fc3 = Dropout(m3_dropout)(m3_fc3)\n",
    "m3_output = Dense(len(classes), activation='sigmoid')(m3_fc3)\n",
    "\n",
    "m3_model = Model(inputs=[m3_input], outputs=[m3_output])\n",
    "m3_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 159571 samples, validate on 63978 samples\n",
      "Epoch 1/5\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0569 - acc: 0.9795\n",
      "Epoch 00001: val_loss improved from inf to 0.07310, saving model to data/models/cnn_multilayer/model1542877635.380672.hdf5\n",
      "\n",
      " train: ROC-AUC - epoch: 1 - score: 0.990770\n",
      " Tox: 0.9891278966931427 - STox: 0.9910711924338175 - Obs: 0.9949118178382583 - Thr: 0.9897739807828515 - Ins: 0.9904676369194964 - IdH: 0.9892700169104734\n",
      "\n",
      " val: ROC-AUC - epoch: 1 - score: 0.976654\n",
      " Tox: 0.9647248585343671 - STox: 0.9867400360938721 - Obs: 0.9747659188617769 - Thr: 0.9851343052316428 - Ins: 0.971281625069828 - IdH: 0.9772788857071107\n",
      "159571/159571 [==============================] - 531s 3ms/step - loss: 0.0569 - acc: 0.9795 - val_loss: 0.0731 - val_acc: 0.9697\n",
      "Epoch 2/5\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0409 - acc: 0.9838\n",
      "Epoch 00002: val_loss improved from 0.07310 to 0.07120, saving model to data/models/cnn_multilayer/model1542877635.380672.hdf5\n",
      "\n",
      " train: ROC-AUC - epoch: 2 - score: 0.994574\n",
      " Tox: 0.9946285060504322 - STox: 0.9925260362551797 - Obs: 0.9964674296623429 - Thr: 0.9962919704316522 - Ins: 0.9928886130700111 - IdH: 0.9946384790644974\n",
      "\n",
      " val: ROC-AUC - epoch: 2 - score: 0.977149\n",
      " Tox: 0.9642103621079968 - STox: 0.9867962574121651 - Obs: 0.9747663030980811 - Thr: 0.9869827854473451 - Ins: 0.9701664430474741 - IdH: 0.9799690609863047\n",
      "159571/159571 [==============================] - 535s 3ms/step - loss: 0.0409 - acc: 0.9838 - val_loss: 0.0712 - val_acc: 0.9714\n",
      "Epoch 3/5\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0345 - acc: 0.9858\n",
      "Epoch 00003: val_loss did not improve\n",
      "\n",
      " train: ROC-AUC - epoch: 3 - score: 0.995940\n",
      " Tox: 0.9961611312395083 - STox: 0.9929689510394262 - Obs: 0.9977457104701077 - Thr: 0.9975465851438649 - Ins: 0.9946882029511651 - IdH: 0.9965264792524166\n",
      "\n",
      " val: ROC-AUC - epoch: 3 - score: 0.977474\n",
      " Tox: 0.9634913798776596 - STox: 0.9868751600165807 - Obs: 0.9736757663156047 - Thr: 0.9883493571865641 - Ins: 0.9706356966185018 - IdH: 0.9818187951389123\n",
      "159571/159571 [==============================] - 535s 3ms/step - loss: 0.0345 - acc: 0.9858 - val_loss: 0.0794 - val_acc: 0.9652\n",
      "Epoch 4/5\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0300 - acc: 0.9876\n",
      "Epoch 00004: val_loss did not improve\n",
      "\n",
      " train: ROC-AUC - epoch: 4 - score: 0.996905\n",
      " Tox: 0.9976688719067558 - STox: 0.9942309795718345 - Obs: 0.9982732435928511 - Thr: 0.9973783458726426 - Ins: 0.9962091065213288 - IdH: 0.9976713123105987\n",
      "\n",
      " val: ROC-AUC - epoch: 4 - score: 0.975074\n",
      " Tox: 0.9615421980704939 - STox: 0.9857945969878138 - Obs: 0.9731395791584241 - Thr: 0.9843331435378965 - Ins: 0.968848059492104 - IdH: 0.9767837185210865\n",
      "159571/159571 [==============================] - 539s 3ms/step - loss: 0.0300 - acc: 0.9876 - val_loss: 0.0776 - val_acc: 0.9675\n",
      "Epoch 5/5\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0267 - acc: 0.9889\n",
      "Epoch 00005: val_loss did not improve\n",
      "\n",
      " train: ROC-AUC - epoch: 5 - score: 0.997524\n",
      " Tox: 0.9982873526221395 - STox: 0.9947582847789426 - Obs: 0.998665600121992 - Thr: 0.998316167378429 - Ins: 0.9970951242942345 - IdH: 0.9980189604840142\n",
      "\n",
      " val: ROC-AUC - epoch: 5 - score: 0.975522\n",
      " Tox: 0.9577371293845496 - STox: 0.9869841758299562 - Obs: 0.9729292356222717 - Thr: 0.9882063602851525 - Ins: 0.9692658331889094 - IdH: 0.9780095264794233\n",
      "159571/159571 [==============================] - 537s 3ms/step - loss: 0.0267 - acc: 0.9889 - val_loss: 0.0860 - val_acc: 0.9673\n"
     ]
    }
   ],
   "source": [
    "m3_model, predictions = train_model(m3_model, X_train_input, Y_train, (X_test_input, Y_test), \\\n",
    "                                    m3_epochs, m3_batch_size, 'adam', 'binary_crossentropy', ['accuracy'], \\\n",
    "                                    m3_weights_path.format(time.time()), random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Dilated CNN\n",
    "This architecture consists of multiple convolutional layers with a fully connected hidden layer on top of it.\n",
    "The first convolutional is a non-dilated layer (dilation rate = 1) whereas layer 2 and 3 specify a gradually growing dilation rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m4_kernel_sizes = [3, 7, 14]\n",
    "m4_dilation_rates = [1, 2, 4]\n",
    "m4_hidden_dim = 100\n",
    "m4_num_filters = [150, 150, 150]\n",
    "m4_dropout = 0.4\n",
    "m4_spatial_dropout = 0.2\n",
    "m4_batch_size = 64\n",
    "m4_epochs = 5\n",
    "\n",
    "m4_weights_path = 'data/models/cnn_dilated/model{}.hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 2000, 300)         97852800  \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 2000, 300)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 2000, 150)         135150    \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 2000, 150)         157650    \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 2000, 150)         315150    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               15100     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 606       \n",
      "=================================================================\n",
      "Total params: 98,476,456\n",
      "Trainable params: 98,476,456\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m4_input = Input((max_comment_length,))\n",
    "m4_word_emb = Embedding(input_dim=len(embedding_matrix), output_dim=embedding_length, input_length=max_comment_length, weights=[embedding_matrix])(m4_input)\n",
    "m4_word_emb = SpatialDropout1D(m4_spatial_dropout)(m4_word_emb)\n",
    "\n",
    "m4_conv1 = Conv1D(kernel_size=m4_kernel_sizes[0], dilation_rate= m4_dilation_rates[0], filters=m4_num_filters[0], padding='same')(m4_word_emb)\n",
    "m4_conv2 = Conv1D(kernel_size=m4_kernel_sizes[1], dilation_rate= m4_dilation_rates[1], filters=m4_num_filters[1], padding='same')(m4_conv1)\n",
    "m4_conv3 = Conv1D(kernel_size=m4_kernel_sizes[2], dilation_rate= m4_dilation_rates[2], filters=m4_num_filters[2], padding='same')(m4_conv2)\n",
    "m4_conv3 = GlobalMaxPooling1D()(m4_conv3)\n",
    "\n",
    "m4_fc4 = Dense(m4_hidden_dim, activation='relu')(m4_conv3)\n",
    "m4_fc4 = Dropout(m4_dropout)(m4_fc4)\n",
    "m4_output = Dense(len(classes), activation='sigmoid')(m4_fc4)\n",
    "\n",
    "m4_model = Model(inputs=[m4_input], outputs=[m4_output])\n",
    "m4_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 159571 samples, validate on 63978 samples\n",
      "Epoch 1/5\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0632 - acc: 0.9780\n",
      "Epoch 00001: val_loss improved from inf to 0.07305, saving model to data/models/cnn_dilated/model1542264015.405812.hdf5\n",
      "\n",
      " train: ROC-AUC - epoch: 1 - score: 0.985956\n",
      " Tox: 0.9888663510080515 - STox: 0.9905932459404572 - Obs: 0.9930193682403294 - Thr: 0.9776521795480431 - Ins: 0.9880621906031104 - IdH: 0.9775403566044827\n",
      "\n",
      " val: ROC-AUC - epoch: 1 - score: 0.970267\n",
      " Tox: 0.9650888761129582 - STox: 0.9877613793340372 - Obs: 0.9755766844278064 - Thr: 0.9689464837069375 - Ins: 0.9664771805704888 - IdH: 0.9577527930048871\n",
      "159571/159571 [==============================] - 868s 5ms/step - loss: 0.0632 - acc: 0.9780 - val_loss: 0.0731 - val_acc: 0.9715\n",
      "Epoch 2/5\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0475 - acc: 0.9820\n",
      "Epoch 00002: val_loss did not improve\n",
      "\n",
      " train: ROC-AUC - epoch: 2 - score: 0.989872\n",
      " Tox: 0.9931744434306217 - STox: 0.9896209423819466 - Obs: 0.9958710009033012 - Thr: 0.9857293871979882 - Ins: 0.9897306483106407 - IdH: 0.9851046670503348\n",
      "\n",
      " val: ROC-AUC - epoch: 2 - score: 0.969027\n",
      " Tox: 0.9656227661977468 - STox: 0.9837255453864101 - Obs: 0.977951752386513 - Thr: 0.9640414818849161 - Ins: 0.9665903832838437 - IdH: 0.956228896842545\n",
      "159571/159571 [==============================] - 879s 6ms/step - loss: 0.0475 - acc: 0.9820 - val_loss: 0.0768 - val_acc: 0.9697\n",
      "Epoch 3/5\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0421 - acc: 0.9835\n",
      "Epoch 00003: val_loss did not improve\n",
      "\n",
      " train: ROC-AUC - epoch: 3 - score: 0.992083\n",
      " Tox: 0.9951703600042883 - STox: 0.9924484461986448 - Obs: 0.9968678980793633 - Thr: 0.9881201035356626 - Ins: 0.9916842878863834 - IdH: 0.9882062082348457\n",
      "\n",
      " val: ROC-AUC - epoch: 3 - score: 0.970268\n",
      " Tox: 0.9624863801885484 - STox: 0.9871270315225329 - Obs: 0.975035461752743 - Thr: 0.9687091712816737 - Ins: 0.9671467755476567 - IdH: 0.9611037239946764\n",
      "159571/159571 [==============================] - 864s 5ms/step - loss: 0.0421 - acc: 0.9835 - val_loss: 0.0753 - val_acc: 0.9684\n",
      "Epoch 4/5\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0373 - acc: 0.9849\n",
      "Epoch 00004: val_loss did not improve\n",
      "\n",
      " train: ROC-AUC - epoch: 4 - score: 0.993524\n",
      " Tox: 0.9965549261519417 - STox: 0.9927694603981748 - Obs: 0.9974931803321396 - Thr: 0.9914543878666585 - Ins: 0.9926123031211587 - IdH: 0.9902577579310677\n",
      "\n",
      " val: ROC-AUC - epoch: 4 - score: 0.970798\n",
      " Tox: 0.9612551012952024 - STox: 0.9863293955850607 - Obs: 0.9754636133455327 - Thr: 0.9721101043438877 - Ins: 0.9649433429587966 - IdH: 0.9646889075801582\n",
      "159571/159571 [==============================] - 868s 5ms/step - loss: 0.0373 - acc: 0.9849 - val_loss: 0.0855 - val_acc: 0.9657\n",
      "Epoch 5/5\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0345 - acc: 0.9858\n",
      "Epoch 00005: val_loss did not improve\n",
      "\n",
      " train: ROC-AUC - epoch: 5 - score: 0.993506\n",
      " Tox: 0.9968769126354873 - STox: 0.9923589123414327 - Obs: 0.9979813127447282 - Thr: 0.9889482157839995 - Ins: 0.9942890477587428 - IdH: 0.9905841302009696\n",
      "\n",
      " val: ROC-AUC - epoch: 5 - score: 0.967552\n",
      " Tox: 0.9585849729300042 - STox: 0.9829740002211158 - Obs: 0.9740266976462093 - Thr: 0.9655106189692226 - Ins: 0.965120540709805 - IdH: 0.9590925970851802\n",
      "159571/159571 [==============================] - 862s 5ms/step - loss: 0.0345 - acc: 0.9858 - val_loss: 0.1146 - val_acc: 0.9576\n"
     ]
    }
   ],
   "source": [
    "m4_model, predictions = train_model(m4_model, X_train_input, Y_train, (X_test_input, Y_test), \\\n",
    "                                    m4_epochs, m4_batch_size, 'adam', 'binary_crossentropy', ['accuracy'], \\\n",
    "                                    m4_weights_path.format(time.time()), random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[[0.74460029 0.        ]\n",
      "    [0.77822825 0.        ]\n",
      "    [0.69525732 0.        ]\n",
      "    [0.74791305 0.        ]\n",
      "    [0.7748494  0.        ]\n",
      "    [0.76914494 0.        ]\n",
      "    [0.70220877 0.        ]]]\n",
      "\n",
      "\n",
      "  [[[0.7288697  0.        ]\n",
      "    [0.72232498 0.        ]\n",
      "    [0.82461435 0.        ]\n",
      "    [0.76629272 0.        ]\n",
      "    [0.49983283 0.        ]\n",
      "    [0.74034114 0.        ]\n",
      "    [0.81981217 0.        ]]]]\n",
      "\n",
      "\n",
      "\n",
      " [[[[0.74851886 0.        ]\n",
      "    [0.71936153 0.        ]\n",
      "    [0.71252383 0.        ]\n",
      "    [0.73859954 0.        ]\n",
      "    [0.85993976 0.        ]\n",
      "    [0.75937671 0.        ]\n",
      "    [0.70131181 0.        ]]]\n",
      "\n",
      "\n",
      "  [[[0.74117915 0.        ]\n",
      "    [0.72410208 0.        ]\n",
      "    [0.85999329 0.        ]\n",
      "    [0.76443229 0.        ]\n",
      "    [0.54663992 0.        ]\n",
      "    [0.73763937 0.        ]\n",
      "    [0.81426793 0.        ]]]]\n",
      "\n",
      "\n",
      "\n",
      " [[[[0.74464543 0.        ]\n",
      "    [0.70973131 0.        ]\n",
      "    [0.72429645 0.        ]\n",
      "    [0.74585292 0.        ]\n",
      "    [0.81777108 0.        ]\n",
      "    [0.75242737 0.        ]\n",
      "    [0.71779347 0.        ]]]\n",
      "\n",
      "\n",
      "  [[[0.74444759 0.        ]\n",
      "    [0.7293004  0.        ]\n",
      "    [0.87894031 0.        ]\n",
      "    [0.77418095 0.        ]\n",
      "    [0.51019726 0.        ]\n",
      "    [0.74243052 0.        ]\n",
      "    [0.83163612 0.        ]]]]\n",
      "\n",
      "\n",
      "\n",
      " [[[[0.74882709 0.        ]\n",
      "    [0.72019154 0.        ]\n",
      "    [0.71409351 0.        ]\n",
      "    [0.74576708 0.        ]\n",
      "    [0.8002008  0.        ]\n",
      "    [0.74121056 0.        ]\n",
      "    [0.77149905 0.        ]]]\n",
      "\n",
      "\n",
      "  [[[0.72475754 0.        ]\n",
      "    [0.72413835 0.        ]\n",
      "    [0.85663984 0.        ]\n",
      "    [0.76216256 0.        ]\n",
      "    [0.44533601 0.        ]\n",
      "    [0.73106504 0.        ]\n",
      "    [0.82920344 0.        ]]]]\n",
      "\n",
      "\n",
      "\n",
      " [[[[0.73718872 0.        ]\n",
      "    [0.73473796 0.        ]\n",
      "    [0.7068057  0.        ]\n",
      "    [0.74935084 0.        ]\n",
      "    [0.80296185 0.        ]\n",
      "    [0.74579125 0.        ]\n",
      "    [0.6834847  0.        ]]]\n",
      "\n",
      "\n",
      "  [[[0.71848545 0.        ]\n",
      "    [0.70498918 0.        ]\n",
      "    [0.84792086 0.        ]\n",
      "    [0.76422764 0.        ]\n",
      "    [0.47442327 0.        ]\n",
      "    [0.72533727 0.        ]\n",
      "    [0.79401448 0.        ]]]]\n",
      "\n",
      "\n",
      "\n",
      " [[[[0.7470479  0.        ]\n",
      "    [0.7219154  0.        ]\n",
      "    [0.71106626 0.        ]\n",
      "    [0.74615335 0.        ]\n",
      "    [0.77585341 0.        ]\n",
      "    [0.7884269  0.        ]\n",
      "    [0.73887207 0.        ]]]\n",
      "\n",
      "\n",
      "  [[[0.72179183 0.        ]\n",
      "    [0.71565178 0.        ]\n",
      "    [0.82729712 0.        ]\n",
      "    [0.75589291 0.        ]\n",
      "    [0.46339017 0.        ]\n",
      "    [0.74531242 0.        ]\n",
      "    [0.82320661 0.        ]]]]\n",
      "\n",
      "\n",
      "\n",
      " [[[[0.73638346 0.        ]\n",
      "    [0.69412078 0.        ]\n",
      "    [0.68583922 0.        ]\n",
      "    [0.75353548 0.        ]\n",
      "    [0.79693775 0.        ]\n",
      "    [0.76614987 0.        ]\n",
      "    [0.72171768 0.        ]]]\n",
      "\n",
      "\n",
      "  [[[0.73847394 0.        ]\n",
      "    [0.72383612 0.        ]\n",
      "    [0.84473508 0.        ]\n",
      "    [0.77230191 0.        ]\n",
      "    [0.51387496 0.        ]\n",
      "    [0.74660927 0.        ]\n",
      "    [0.82948631 0.        ]]]]\n",
      "\n",
      "\n",
      "\n",
      " [[[[0.7390005  0.        ]\n",
      "    [0.72290503 0.        ]\n",
      "    [0.71207534 0.        ]\n",
      "    [0.76214082 0.        ]\n",
      "    [0.81475904 0.        ]\n",
      "    [0.7215958  0.        ]\n",
      "    [0.70052696 0.        ]]]\n",
      "\n",
      "\n",
      "  [[[0.7318076  0.        ]\n",
      "    [0.72357016 0.        ]\n",
      "    [0.83953722 0.        ]\n",
      "    [0.77066473 0.        ]\n",
      "    [0.52825142 0.        ]\n",
      "    [0.72004179 0.        ]\n",
      "    [0.80878027 0.        ]]]]\n",
      "\n",
      "\n",
      "\n",
      " [[[[0.73403992 0.        ]\n",
      "    [0.68991753 0.        ]\n",
      "    [0.70927234 0.        ]\n",
      "    [0.72527307 0.        ]\n",
      "    [0.78639558 0.        ]\n",
      "    [0.80361757 0.        ]\n",
      "    [0.68976343 0.        ]]]\n",
      "\n",
      "\n",
      "  [[[0.72151441 0.        ]\n",
      "    [0.71794872 0.        ]\n",
      "    [0.82293763 0.        ]\n",
      "    [0.7631858  0.        ]\n",
      "    [0.49782681 0.        ]\n",
      "    [0.71529566 0.        ]\n",
      "    [0.81189183 0.        ]]]]\n",
      "\n",
      "\n",
      "\n",
      " [[[[0.73693468 0.        ]\n",
      "    [0.71496675 0.        ]\n",
      "    [0.72911761 0.        ]\n",
      "    [0.74096011 0.        ]\n",
      "    [0.75527108 0.        ]\n",
      "    [0.74769008 0.        ]\n",
      "    [0.73360242 0.        ]]]\n",
      "\n",
      "\n",
      "  [[[0.73157633 0.        ]\n",
      "    [0.73012246 0.        ]\n",
      "    [0.88195842 0.        ]\n",
      "    [0.76549274 0.        ]\n",
      "    [0.45703778 0.        ]\n",
      "    [0.72926386 0.        ]\n",
      "    [0.82558271 0.        ]]]]]\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
