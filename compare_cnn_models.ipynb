{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/philipp/miniconda3/envs/tensorflow/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import utils\n",
    "import time\n",
    "\n",
    "from keras.models import Model, Input\n",
    "from keras.layers import Dense, Conv1D, BatchNormalization, GlobalMaxPooling1D, Dropout, \\\n",
    "    Embedding, Concatenate, SpatialDropout1D, MaxPooling1D\n",
    "\n",
    "from utils.preprocessing_utils import tokenize_sentences, convert_tokens_to_padded_sequence\n",
    "from utils.dataset_utils import load_data_from_csv\n",
    "from utils.embedding_utils import load_word2vec_embeddings, create_initial_embedding_matrix\n",
    "from utils.training_utils import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils.keras_utils' from '/home/philipp/work/gitprojects/toxic-comment-experiments/utils/keras_utils.py'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import utils\n",
    "importlib.reload(utils.embedding_utils)\n",
    "importlib.reload(utils.dataset_utils)\n",
    "importlib.reload(utils.preprocessing_utils)\n",
    "importlib.reload(utils.training_utils)\n",
    "importlib.reload(utils.keras_utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Global parameters which hold for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_seed = 2018\n",
    "classes = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']\n",
    "features = 'comment_text'\n",
    "np.random.seed(random_seed)\n",
    "path_train_data = 'data/kaggle/train.csv'\n",
    "path_test_data = 'data/kaggle/test_complete.csv'\n",
    "path_tokenizer = 'data/models/word_tokenizer.pickle'\n",
    "\n",
    "embedding_length = 300\n",
    "path_embeddings = 'data/embeddings/GoogleNews-vectors-negative300.bin.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load train and test data and pretrained word2vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, Y_train = load_data_from_csv(path_train_data, features, classes)\n",
    "X_test, Y_test = load_data_from_csv(path_test_data, features, classes)\n",
    "\n",
    "emb_idx, emb_mean, emb_std = load_word2vec_embeddings(path_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing and tokenizatin of train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_tok = tokenize_sentences(X_train)\n",
    "del X_train\n",
    "X_test_tok = tokenize_sentences(X_test)\n",
    "del X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create initial embedding matrix for neural network and word -> idx mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens: 326175\n",
      "Number of tokens found in pretrained embeddings: 74211\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix, word_embedding_mapping = create_initial_embedding_matrix(X_train_tok, X_test_tok, emb_idx, emb_mean, emb_std, embedding_length, debug=True)\n",
    "del emb_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform comments in train and test data to padded matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_len_train = X_train_tok.apply(lambda x: len(x)).max()\n",
    "max_len_test = X_test_tok.apply(lambda x: len(x)).max()\n",
    "# limit length to 2000, otherwise we get a MemoryError\n",
    "max_comment_length = 2000 #max(max_len_train, 2000)\n",
    "X_train_input = convert_tokens_to_padded_sequence(X_train_tok, word_embedding_mapping, max_comment_length)\n",
    "del X_train_tok\n",
    "X_test_input = convert_tokens_to_padded_sequence(X_test_tok, word_embedding_mapping, max_comment_length)\n",
    "del X_test_tok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Singlelayer CNN with a single window size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This simple CNN consists of an embedding layer, a single convolution layer with a fixed window size and a fully connected hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m1_kernel_size = 3\n",
    "m1_hidden_dim = 100\n",
    "m1_num_filters = 150\n",
    "m1_dropout = 0.4\n",
    "m1_batch_size = 64\n",
    "m1_epochs = 5\n",
    "\n",
    "m1_weights_path = 'data/models/cnn_simple/model{}.hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 2000, 300)         97852800  \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 2000, 150)         135150    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               15100     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 606       \n",
      "=================================================================\n",
      "Total params: 98,003,656\n",
      "Trainable params: 98,003,656\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m1_input = Input((max_comment_length,))\n",
    "m1_word_emb = Embedding(input_dim=len(embedding_matrix), output_dim=embedding_length, input_length=max_comment_length, weights=[embedding_matrix])(m1_input)\n",
    "\n",
    "m1_conv1 = Conv1D(kernel_size=m1_kernel_size, filters=m1_num_filters, padding='same')(m1_word_emb)\n",
    "m1_conv1 = GlobalMaxPooling1D()(m1_conv1)\n",
    "\n",
    "m1_fc2 = Dense(m1_hidden_dim, activation='relu')(m1_conv1)\n",
    "m1_dropout2 = Dropout(m1_dropout)(m1_fc2)\n",
    "m1_output = Dense(len(classes), activation='sigmoid')(m1_dropout2)\n",
    "\n",
    "m1_model = Model(inputs=[m1_input], outputs=[m1_output])\n",
    "m1_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 159571 samples, validate on 63978 samples\n",
      "Epoch 1/5\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0555 - acc: 0.9800\n",
      "Epoch 00001: val_loss improved from inf to 0.08070, saving model to data/models/cnn_simple/model1541939176.8092248\n",
      "\n",
      " train: ROC-AUC - epoch: 1 - score: 0.992765\n",
      " Tox: 0.9913826599695793 - STox: 0.9920993534512523 - Obs: 0.9953910449917467 - Thr: 0.9931456633073253 - Ins: 0.9920350283093564 - IdH: 0.9925364710971035\n",
      "\n",
      " val: ROC-AUC - epoch: 1 - score: 0.978407\n",
      " Tox: 0.9664115678676495 - STox: 0.9880273008151512 - Obs: 0.9742093918974234 - Thr: 0.9872715291905804 - Ins: 0.9729170176667217 - IdH: 0.9816030794004413\n",
      "159571/159571 [==============================] - 402s 3ms/step - loss: 0.0555 - acc: 0.9800 - val_loss: 0.0807 - val_acc: 0.9665\n",
      "Epoch 2/5\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0364 - acc: 0.9853\n",
      "Epoch 00002: val_loss improved from 0.08070 to 0.06677, saving model to data/models/cnn_simple/model1541939176.8092248\n",
      "\n",
      " train: ROC-AUC - epoch: 2 - score: 0.996276\n",
      " Tox: 0.9966820194189336 - STox: 0.9939639257929422 - Obs: 0.9976117826725686 - Thr: 0.997463846243245 - Ins: 0.995484808581766 - IdH: 0.9964485058560258\n",
      "\n",
      " val: ROC-AUC - epoch: 2 - score: 0.978750\n",
      " Tox: 0.9657501524942339 - STox: 0.9874653018086731 - Obs: 0.9762802480649354 - Thr: 0.9879868481498513 - Ins: 0.9738791503723969 - IdH: 0.9811362391962312\n",
      "159571/159571 [==============================] - 409s 3ms/step - loss: 0.0364 - acc: 0.9853 - val_loss: 0.0668 - val_acc: 0.9726\n",
      "Epoch 3/5\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0273 - acc: 0.9887\n",
      "Epoch 00003: val_loss did not improve\n",
      "\n",
      " train: ROC-AUC - epoch: 3 - score: 0.998059\n",
      " Tox: 0.9987750352295482 - STox: 0.9962163412624242 - Obs: 0.9988522432471025 - Thr: 0.9991253569824571 - Ins: 0.9974621900196275 - IdH: 0.9979234214172839\n",
      "\n",
      " val: ROC-AUC - epoch: 3 - score: 0.977346\n",
      " Tox: 0.9618358359860975 - STox: 0.985172500069286 - Obs: 0.9746534342454413 - Thr: 0.9890095286921723 - Ins: 0.9717434885741931 - IdH: 0.9816606435570592\n",
      "159571/159571 [==============================] - 417s 3ms/step - loss: 0.0273 - acc: 0.9887 - val_loss: 0.0764 - val_acc: 0.9698\n",
      "Epoch 4/5\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0204 - acc: 0.9918\n",
      "Epoch 00004: val_loss did not improve\n",
      "\n",
      " train: ROC-AUC - epoch: 4 - score: 0.998989\n",
      " Tox: 0.9994979364914918 - STox: 0.9979606977322694 - Obs: 0.9993952306616709 - Thr: 0.9996149787602194 - Ins: 0.9986895210165977 - IdH: 0.9987760753004984\n",
      "\n",
      " val: ROC-AUC - epoch: 4 - score: 0.974544\n",
      " Tox: 0.9578474579415458 - STox: 0.9838861563067447 - Obs: 0.9723476726292486 - Thr: 0.9870420206502688 - Ins: 0.9679370307720304 - IdH: 0.9782053955707611\n",
      "159571/159571 [==============================] - 407s 3ms/step - loss: 0.0204 - acc: 0.9918 - val_loss: 0.0869 - val_acc: 0.9672\n",
      "Epoch 5/5\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0153 - acc: 0.9939\n",
      "Epoch 00005: val_loss did not improve\n",
      "\n",
      " train: ROC-AUC - epoch: 5 - score: 0.999398\n",
      " Tox: 0.9998306359702658 - STox: 0.9987625932783251 - Obs: 0.9997393564077733 - Thr: 0.9997768272009107 - Ins: 0.9993222103840509 - IdH: 0.9989584999732026\n",
      "\n",
      " val: ROC-AUC - epoch: 5 - score: 0.972170\n",
      " Tox: 0.956791424026102 - STox: 0.9810089098688524 - Obs: 0.9703768167686764 - Thr: 0.9817547399496552 - Ins: 0.9652846618739936 - IdH: 0.9778054878510104\n",
      "159571/159571 [==============================] - 415s 3ms/step - loss: 0.0153 - acc: 0.9939 - val_loss: 0.1094 - val_acc: 0.9632\n"
     ]
    }
   ],
   "source": [
    "m1_model, predictions = train_model(m1_model, X_train_input, Y_train, (X_test_input, Y_test), \\\n",
    "                                    m1_epochs, m1_batch_size, 'adam', 'binary_crossentropy', ['accuracy'], \\\n",
    "                                    m1_weights_path.format(time.time()), random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Singlelayer CNN with multiple window sizes\n",
    "This CNN consists of an embedding layer, a convolution layer with multiple window sizes which get concatenated afterwards. On top of that there is a fully connected hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m2_kernel_sizes = [3, 4, 5]\n",
    "m2_hidden_dim = 100\n",
    "m2_num_filters = [100, 100, 100]\n",
    "m2_dropout = 0.4\n",
    "m2_spatial_dropout = 0.2\n",
    "m2_batch_size = 64\n",
    "m2_epochs = 5\n",
    "\n",
    "m2_weights_path = 'data/models/cnn_multiwindowsizes/model{}.hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 2000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 2000, 300)    97852800    input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_3 (SpatialDro (None, 2000, 300)    0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 2000, 100)    90100       spatial_dropout1d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 2000, 100)    120100      spatial_dropout1d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 2000, 100)    150100      spatial_dropout1d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_7 (GlobalM (None, 100)          0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_8 (GlobalM (None, 100)          0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_9 (GlobalM (None, 100)          0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 300)          0           global_max_pooling1d_7[0][0]     \n",
      "                                                                 global_max_pooling1d_8[0][0]     \n",
      "                                                                 global_max_pooling1d_9[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 100)          30100       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 100)          0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 6)            606         dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 98,243,806\n",
      "Trainable params: 98,243,806\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m2_input = Input((max_comment_length,))\n",
    "m2_word_emb = Embedding(input_dim=len(embedding_matrix), output_dim=embedding_length, input_length=max_comment_length, weights=[embedding_matrix])(m2_input)\n",
    "m2_word_emb = SpatialDropout1D(m2_spatial_dropout)(m2_word_emb)\n",
    "\n",
    "m2_conv1 = Conv1D(kernel_size=m2_kernel_sizes[0], filters=m2_num_filters[0], padding='same')(m2_word_emb)\n",
    "m2_conv1 = GlobalMaxPooling1D()(m2_conv1)\n",
    "\n",
    "m2_conv2 = Conv1D(kernel_size=m2_kernel_sizes[1], filters=m2_num_filters[1], padding='same')(m2_word_emb)\n",
    "m2_conv2 = GlobalMaxPooling1D()(m2_conv2)\n",
    "\n",
    "m2_conv3 = Conv1D(kernel_size=m2_kernel_sizes[2], filters=m2_num_filters[2], padding='same')(m2_word_emb)\n",
    "m2_conv3 = GlobalMaxPooling1D()(m2_conv3)\n",
    "\n",
    "m2_concat4 = Concatenate()([m2_conv1, m2_conv2, m2_conv3])\n",
    "\n",
    "m2_fc5 = Dense(m2_hidden_dim, activation='relu')(m2_concat4)\n",
    "m2_fc5 = Dropout(m2_dropout)(m2_fc5)\n",
    "m2_output = Dense(len(classes), activation='sigmoid')(m2_fc5)\n",
    "\n",
    "m2_model = Model(inputs=[m2_input], outputs=[m2_output])\n",
    "m2_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 159571 samples, validate on 63978 samples\n",
      "Epoch 1/5\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0551 - acc: 0.9801\n",
      "Epoch 00001: val_loss improved from inf to 0.08369, saving model to data/models/cnn_multiwindowsizes/model1541932408.2893183\n",
      "\n",
      " train: ROC-AUC - epoch: 0 - score: 0.992644\n",
      " Tox: 0.9916101666633795 - STox: 0.9920910052921812 - Obs: 0.995355572761399 - Thr: 0.9926842150983135 - Ins: 0.9914407411046907 - IdH: 0.9926831569318832\n",
      "\n",
      " val: ROC-AUC - epoch: 0 - score: 0.978808\n",
      " Tox: 0.9668416790454769 - STox: 0.9884707745738456 - Obs: 0.9747124942865073 - Thr: 0.9866755725097227 - Ins: 0.9731549503444628 - IdH: 0.9829946756818101\n",
      "159571/159571 [==============================] - 693s 4ms/step - loss: 0.0551 - acc: 0.9801 - val_loss: 0.0837 - val_acc: 0.9651\n",
      "Epoch 2/5\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0382 - acc: 0.9846\n",
      "Epoch 00002: val_loss improved from 0.08369 to 0.08026, saving model to data/models/cnn_multiwindowsizes/model1541932408.2893183\n",
      "\n",
      " train: ROC-AUC - epoch: 1 - score: 0.995974\n",
      " Tox: 0.9964034740653277 - STox: 0.9938659862305181 - Obs: 0.9973711965699472 - Thr: 0.9971531019710662 - Ins: 0.9944256670316292 - IdH: 0.9966244235582392\n",
      "\n",
      " val: ROC-AUC - epoch: 1 - score: 0.979081\n",
      " Tox: 0.9654433854945306 - STox: 0.9882466175006063 - Obs: 0.9754851485545409 - Thr: 0.9897576611295997 - Ins: 0.9726762128143929 - IdH: 0.9828766169911453\n",
      "159571/159571 [==============================] - 691s 4ms/step - loss: 0.0382 - acc: 0.9846 - val_loss: 0.0803 - val_acc: 0.9662\n",
      "Epoch 3/5\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0301 - acc: 0.9875\n",
      "Epoch 00003: val_loss improved from 0.08026 to 0.07269, saving model to data/models/cnn_multiwindowsizes/model1541932408.2893183\n",
      "\n",
      " train: ROC-AUC - epoch: 2 - score: 0.997532\n",
      " Tox: 0.9980506431939761 - STox: 0.9949767279439137 - Obs: 0.9984261543436528 - Thr: 0.9987082566663792 - Ins: 0.9968820530283885 - IdH: 0.9981477026501685\n",
      "\n",
      " val: ROC-AUC - epoch: 2 - score: 0.979174\n",
      " Tox: 0.9640717968722344 - STox: 0.988312883694434 - Obs: 0.9760444550528617 - Thr: 0.9903432497918778 - Ins: 0.9733448897558915 - IdH: 0.9829255232144499\n",
      "159571/159571 [==============================] - 694s 4ms/step - loss: 0.0301 - acc: 0.9875 - val_loss: 0.0727 - val_acc: 0.9697\n",
      "Epoch 4/5\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0240 - acc: 0.9900\n",
      "Epoch 00004: val_loss did not improve\n",
      "\n",
      " train: ROC-AUC - epoch: 3 - score: 0.998578\n",
      " Tox: 0.9991663169681991 - STox: 0.9969683601794678 - Obs: 0.9991316708623943 - Thr: 0.9991718417271632 - Ins: 0.9980022866269541 - IdH: 0.9990299011493983\n",
      "\n",
      " val: ROC-AUC - epoch: 3 - score: 0.977178\n",
      " Tox: 0.9611809730992911 - STox: 0.9856088631698192 - Obs: 0.9747886112736901 - Thr: 0.9897340265066012 - Ins: 0.9715066811527716 - IdH: 0.9802470694449724\n",
      "159571/159571 [==============================] - 693s 4ms/step - loss: 0.0240 - acc: 0.9900 - val_loss: 0.0953 - val_acc: 0.9604\n",
      "Epoch 5/5\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0194 - acc: 0.9920\n",
      "Epoch 00005: val_loss did not improve\n",
      "\n",
      " train: ROC-AUC - epoch: 4 - score: 0.999146\n",
      " Tox: 0.9996614606948154 - STox: 0.9978092085095899 - Obs: 0.9996097866696214 - Thr: 0.9993552296337184 - Ins: 0.998972330288698 - IdH: 0.9994658096725532\n",
      "\n",
      " val: ROC-AUC - epoch: 4 - score: 0.975623\n",
      " Tox: 0.9601495677401172 - STox: 0.9843677106383627 - Obs: 0.9717775985264238 - Thr: 0.9874909670031677 - Ins: 0.9697934603350785 - IdH: 0.9801557837480913\n",
      "159571/159571 [==============================] - 691s 4ms/step - loss: 0.0194 - acc: 0.9920 - val_loss: 0.0939 - val_acc: 0.9630\n"
     ]
    }
   ],
   "source": [
    "m2_model, predictions = train_model(m2_model, X_train_input, Y_train, (X_test_input, Y_test), \\\n",
    "                                    m2_epochs, m2_batch_size, 'adam', 'binary_crossentropy', ['accuracy'], \\\n",
    "                                    m2_weights_path.format(time.time()), random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Multilayer CNN\n",
    "This architecture consists of multiple convolutional layers with a fully connected hidden layer on top of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m3_kernel_sizes = [3, 3]\n",
    "m3_hidden_dim = 100\n",
    "m3_num_filters = [150, 150]\n",
    "m3_dropout = 0.4\n",
    "m3_spatial_dropout = 0.2\n",
    "m3_batch_size = 64\n",
    "m3_epochs = 5\n",
    "\n",
    "m3_weights_path = 'data/models/cnn_multilayer/model{}.hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_4 (Embedding)      (None, 2000, 300)         97852800  \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_2 (Spatial (None, 2000, 300)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 2000, 150)         135150    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1000, 150)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 1000, 150)         67650     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               15100     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 606       \n",
      "=================================================================\n",
      "Total params: 98,071,306\n",
      "Trainable params: 98,071,306\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m3_input = Input((max_comment_length,))\n",
    "m3_word_emb = Embedding(input_dim=len(embedding_matrix), output_dim=embedding_length, input_length=max_comment_length, weights=[embedding_matrix])(m3_input)\n",
    "m3_word_emb = SpatialDropout1D(m3_spatial_dropout)(m3_word_emb)\n",
    "\n",
    "m3_conv1 = Conv1D(kernel_size=m3_kernel_sizes[0], filters=m3_num_filters[0], padding='same')(m3_word_emb)\n",
    "m3_conv1 = MaxPooling1D(2, strides=2)(m3_conv1)\n",
    "\n",
    "m3_conv2 = Conv1D(kernel_size=m3_kernel_sizes[1], filters=m3_num_filters[1], padding='same')(m3_conv1)\n",
    "m3_conv2 = GlobalMaxPooling1D()(m3_conv2)\n",
    "\n",
    "m3_fc3 = Dense(m3_hidden_dim, activation='relu')(m3_conv2)\n",
    "m3_fc3 = Dropout(m3_dropout)(m3_fc3)\n",
    "m3_output = Dense(len(classes), activation='sigmoid')(m3_fc3)\n",
    "\n",
    "m3_model = Model(inputs=[m3_input], outputs=[m3_output])\n",
    "m3_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 159571 samples, validate on 63978 samples\n",
      "Epoch 1/5\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0574 - acc: 0.9795\n",
      "Epoch 00001: val_loss improved from inf to 0.08096, saving model to data/models/cnn_multilayer/model1541936318.5183825\n",
      "\n",
      " train: ROC-AUC - epoch: 1 - score: 0.989335\n",
      " Tox: 0.9896669404061503 - STox: 0.9917272759816061 - Obs: 0.9946295644743336 - Thr: 0.9845237557033232 - Ins: 0.9894297039516081 - IdH: 0.9860304096020925\n",
      "\n",
      " val: ROC-AUC - epoch: 1 - score: 0.974785\n",
      " Tox: 0.965427848158859 - STox: 0.9879879994364589 - Obs: 0.9758918435831798 - Thr: 0.9786274631197687 - Ins: 0.9696245200860109 - IdH: 0.9711480810290207\n",
      "159571/159571 [==============================] - 486s 3ms/step - loss: 0.0574 - acc: 0.9795 - val_loss: 0.0810 - val_acc: 0.9673\n",
      "Epoch 2/5\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0411 - acc: 0.9838\n",
      "Epoch 00002: val_loss improved from 0.08096 to 0.06994, saving model to data/models/cnn_multilayer/model1541936318.5183825\n",
      "\n",
      " train: ROC-AUC - epoch: 2 - score: 0.994595\n",
      " Tox: 0.9949774168710069 - STox: 0.9930609038188889 - Obs: 0.9969585800966493 - Thr: 0.9944555665935456 - Ins: 0.993353808031573 - IdH: 0.9947626537513652\n",
      "\n",
      " val: ROC-AUC - epoch: 2 - score: 0.977750\n",
      " Tox: 0.9658541824380198 - STox: 0.987521523126966 - Obs: 0.9759580400833244 - Thr: 0.986588986548109 - Ins: 0.9709720591049001 - IdH: 0.9796049282910002\n",
      "159571/159571 [==============================] - 491s 3ms/step - loss: 0.0411 - acc: 0.9838 - val_loss: 0.0699 - val_acc: 0.9716\n",
      "Epoch 3/5\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0336 - acc: 0.9862\n",
      "Epoch 00003: val_loss did not improve\n",
      "\n",
      " train: ROC-AUC - epoch: 3 - score: 0.996636\n",
      " Tox: 0.9971489508381144 - STox: 0.9942212939610842 - Obs: 0.9979812238526913 - Thr: 0.9984626173365033 - Ins: 0.9953856181632795 - IdH: 0.996617333840391\n",
      "\n",
      " val: ROC-AUC - epoch: 3 - score: 0.977001\n",
      " Tox: 0.9627352626350097 - STox: 0.9866219391989896 - Obs: 0.9746669791369168 - Thr: 0.9887554193335825 - Ins: 0.9699995557285649 - IdH: 0.9792254222141079\n",
      "159571/159571 [==============================] - 499s 3ms/step - loss: 0.0336 - acc: 0.9862 - val_loss: 0.0862 - val_acc: 0.9627\n",
      "Epoch 4/5\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0283 - acc: 0.9883\n",
      "Epoch 00004: val_loss did not improve\n",
      "\n",
      " train: ROC-AUC - epoch: 4 - score: 0.997611\n",
      " Tox: 0.9983919696272395 - STox: 0.9951480249450215 - Obs: 0.9986361095033922 - Thr: 0.9987721846964751 - Ins: 0.9969416420141656 - IdH: 0.9977768705818919\n",
      "\n",
      " val: ROC-AUC - epoch: 4 - score: 0.976162\n",
      " Tox: 0.9599103282279533 - STox: 0.9851794179686417 - Obs: 0.973968343161866 - Thr: 0.9881317774418226 - Ins: 0.9704769101812742 - IdH: 0.9793048310024697\n",
      "159571/159571 [==============================] - 501s 3ms/step - loss: 0.0283 - acc: 0.9883 - val_loss: 0.0763 - val_acc: 0.9714\n",
      "Epoch 5/5\n",
      "159552/159571 [============================>.] - ETA: 0s - loss: 0.0241 - acc: 0.9901\n",
      "Epoch 00005: val_loss did not improve\n",
      "\n",
      " train: ROC-AUC - epoch: 5 - score: 0.998216\n",
      " Tox: 0.9988083275877482 - STox: 0.9962762964034217 - Obs: 0.9990854920365116 - Thr: 0.9990512969874966 - Ins: 0.9977957460679023 - IdH: 0.9982815072933644\n",
      "\n",
      " val: ROC-AUC - epoch: 5 - score: 0.973819\n",
      " Tox: 0.9574914395024513 - STox: 0.9866768968762236 - Obs: 0.9714556871482759 - Thr: 0.9868481870125964 - Ins: 0.9671800537382902 - IdH: 0.9732601283611874\n",
      "159571/159571 [==============================] - 505s 3ms/step - loss: 0.0241 - acc: 0.9901 - val_loss: 0.0875 - val_acc: 0.9626\n"
     ]
    }
   ],
   "source": [
    "m3_model, predictions = train_model(m3_model, X_train_input, Y_train, (X_test_input, Y_test), \\\n",
    "                                    m3_epochs, m3_batch_size, 'adam', 'binary_crossentropy', ['accuracy'], \\\n",
    "                                    m3_weights_path.format(time.time()), random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
